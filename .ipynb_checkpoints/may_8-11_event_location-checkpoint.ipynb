{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde33ad6-cd24-4507-af27-f3dc6118427d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import obspy\n",
    "import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "from datetime import timezone\n",
    "import types\n",
    "import pickle\n",
    "from location.compute_backazimuths import compute_backazimuths\n",
    "from figures.figures import plot_catalog_and_big_event_backazimuths, plot_big_event_backazimuths, transform_imagery, get_station_coordinates, get_station_grid_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edfa458-f6aa-45a8-95fa-f52a2e18b4c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Manually pick events that occur within the time window constrained by imagery\n",
    "\n",
    "'''\n",
    "\n",
    "# get data\n",
    "st = obspy.read(\"data/MSEED/may_8-11_velocity_100000s_downsampled.MSEED\")\n",
    "\n",
    "# set low cut periods of data to be dispayed\n",
    "freq = [10,100,1000]\n",
    "\n",
    "# put data into dictionary\n",
    "window_start = obspy.UTCDateTime(2012,5,8,10,18)\n",
    "window_end = obspy.UTCDateTime(2012,5,11,3,13)\n",
    "data_dict = {}\n",
    "for tr in st:\n",
    "    for f in freq: \n",
    "        key = tr.stats.station+tr.stats.channel+str(f)\n",
    "        st_filt = tr.copy().filter(\"highpass\",freq=1/f)\n",
    "        data_dict[key] = st_filt.trim(starttime=window_start,endtime=window_end).data*1000\n",
    "\n",
    "# get time vector\n",
    "t = st_filt.times(type=\"matplotlib\")\n",
    "    \n",
    "# make plot\n",
    "nrows = len(freq)\n",
    "fig,ax = plt.subplots(nrows,1,figsize=[15,10])\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "# plot the data\n",
    "for i in range(nrows):\n",
    "    ax[i].plot(t,data_dict[\"PIG2HHZ\"+str(freq[i])], lw=2,color='k')\n",
    "    ax[i].set_title(\"PIG2 HHZ\\n\\n>\"+str(freq[i])+\"s\",y=0.8)\n",
    "    ax[i].set_ylabel(\"Velocity (mm/s)\")\n",
    "    ax[i].set_xlabel(\"Time\")\n",
    "    ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\\n%H:%M:%S'))\n",
    "    ax[i].set_xlim([t[0],t[-1]])\n",
    "    ax[nrows-1].get_shared_x_axes().join(ax[nrows-1],ax[i])\n",
    "\n",
    "# define object for updating data when buttons are pressed\n",
    "class metadata:\n",
    "    def __init__(self,station,channel):\n",
    "        self._station = station\n",
    "        self._channel = channel\n",
    "\n",
    "    def select_component(self,component_id,component_type):\n",
    "        def clicked(event):\n",
    "            if component_type == \"station\":\n",
    "                self._station = component_id\n",
    "            if component_type == \"channel\":\n",
    "                self._channel = component_id\n",
    "            for i in range(nrows):\n",
    "                key = self._station+self._channel+str(freq[i])\n",
    "                ax[i].get_lines()[0].set_ydata(data_dict[key])\n",
    "                ax[i].relim()\n",
    "                ax[i].autoscale()\n",
    "                ax[i].set_xlim([t[0],t[-1]])\n",
    "                ax[i].set_title(self._station+\" \"+self._channel+\"\\n\\n>\"+str(freq[i])+\"s\",y=0.8)\n",
    "            plt.draw()\n",
    "        return clicked\n",
    "    \n",
    "def mouse_event(event):\n",
    "    print('x: {} and y: {}'.format(event.xdata, event.ydata))\n",
    "\n",
    "# take care of arrival time storage\n",
    "cid = fig.canvas.mpl_connect('button_press_event', mouse_event)\n",
    "    \n",
    "# make instances of the widget\n",
    "column0 = metadata(\"PIG2\",\"HHZ\")  \n",
    "\n",
    "# add each set of buttons\n",
    "axbutton = plt.axes([0.125, 0.075, 0.05, 0.05])\n",
    "pig2_b0 = Button(axbutton, 'PIG2')\n",
    "pig2_b0.on_clicked(column0.select_component(\"PIG2\",\"station\"))\n",
    "axbutton = plt.axes([0.2, 0.075, 0.05, 0.05])\n",
    "pig4_b0 = Button(axbutton, 'PIG4')\n",
    "pig4_b0.on_clicked(column0.select_component(\"PIG4\",\"station\"))\n",
    "axbutton = plt.axes([0.275, 0.075, 0.05, 0.05])\n",
    "pig5_b0 = Button(axbutton, 'PIG5')\n",
    "pig5_b0.on_clicked(column0.select_component(\"PIG5\",\"station\"))\n",
    "plt.text(-4,0.4,\"Stations\")\n",
    "axbutton = plt.axes([0.125, 0.01, 0.05, 0.05])\n",
    "hhz_b0 = Button(axbutton, 'HHZ')\n",
    "hhz_b0.on_clicked(column0.select_component(\"HHZ\",\"channel\"))\n",
    "axbutton = plt.axes([0.2, 0.01, 0.05, 0.05])\n",
    "hhn_b0 = Button(axbutton, 'HHN')\n",
    "hhn_b0.on_clicked(column0.select_component(\"HHN\",\"channel\"))\n",
    "axbutton = plt.axes([0.275, 0.01, 0.05, 0.05])\n",
    "hhe_b0 = Button(axbutton, 'HHE')\n",
    "hhe_b0.on_clicked(column0.select_component(\"HHE\",\"channel\"))\n",
    "plt.text(-4,0.4,\"Channels\")\n",
    "\n",
    "# make pick handling\n",
    "class picks:\n",
    "    start_time = []\n",
    "    end_time = []\n",
    "    event_windows = []\n",
    "    def picker(self):\n",
    "        def clicked(event):\n",
    "            if plt.get_current_fig_manager().toolbar.mode != '': return\n",
    "            if event.button == 1:\n",
    "                self.start_time = matplotlib.dates.num2date(event.xdata)\n",
    "                for axis in ax:\n",
    "                    axis.axvline(event.xdata,0,1,color ='g',linestyle='--')\n",
    "            if event.button == 3:\n",
    "                self.end_time = matplotlib.dates.num2date(event.xdata)\n",
    "                self.event_windows.append([self.start_time,self.end_time])\n",
    "                for axis in ax:\n",
    "                    axis.axvline(event.xdata,0,1,color ='r',linestyle='--')\n",
    "                np.save('outputs/detections_new.npy',self.event_windows,allow_pickle=True)\n",
    "        return clicked\n",
    "    \n",
    "detections = picks()\n",
    "cid = fig.canvas.mpl_connect('button_press_event', detections.picker())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ab664-da09-4310-bd42-1c70e1bef3e6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "Calculate backazimuths for all manually picked events\n",
    "\n",
    "'''\n",
    "\n",
    "# initialize location parameter object and set parameters for backazimuth computation\n",
    "l = types.SimpleNamespace()\n",
    "l.win_len = 20\n",
    "l.slide = 5\n",
    "l.stations = [\"PIG2\",\"PIG4\",\"PIG5\"]\n",
    "l.network = \"XC\"\n",
    "\n",
    "# load and sort catalog\n",
    "detection_times = np.load('outputs/detections.npy',allow_pickle=True)\n",
    "sort_indices = np.argsort(detection_times[:,0])\n",
    "l.detection_times = detection_times[sort_indices]\n",
    "\n",
    "# set the coordinate system in which we will do all grid-based calculations\n",
    "l.crs = \"EPSG:3245\"\n",
    "\n",
    "# set signal-to-noise ratio for throwing out stations and sta/lta ratio for throwing out individual windows in backazimuth computation\n",
    "l.snr_threshold = 0\n",
    "l.stalta_threshold = 0\n",
    "\n",
    "# specify method for correcting pca components \n",
    "l.pca_correction = \"distance\"\n",
    "l.centroid = \"fixed\"\n",
    "\n",
    "# specify parameters for cross correlation based determination of station of first arrival\n",
    "l.max_shift = 1000\n",
    "l.freq = [0.05,10]\n",
    "l.fs = 100\n",
    "\n",
    "# specify paths to data and me tadata\n",
    "#l.data_path = \"data/MSEED/no_IR/\"\n",
    "#l.xml_path = \"data/XML/\"\n",
    "l.data_path = \"/media/Data/Data/PIG/MSEED/noIR/\"\n",
    "l.xml_path = \"/media/Data/Data/PIG/XML/HH/\"\n",
    "l.filename = \"outputs/event_backazimuths_\" + '_'.join(l.stations) + \"_\" + l.pca_correction + \"_pca_\" + l.centroid + \"_centroid\"\n",
    "l.n_procs = 10\n",
    "\n",
    "# run the backazimuth code\n",
    "b = compute_backazimuths(l)\n",
    "\n",
    "# save the output\n",
    "baz_file = open(l.filename + \".pickle\", \"wb\")\n",
    "pickle.dump(b, baz_file)\n",
    "baz_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2c699-8e6a-4db4-95f8-fa65c8f5b0e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Plot the locations of all the detected events\n",
    "\n",
    "'''\n",
    "\n",
    "# load the results of polarization analysis\n",
    "baz_file = open(\"outputs/event_backazimuths_PIG2_PIG4_PIG5_distance_pca_fixed_centroid.pickle\", \"rb\")\n",
    "b = pickle.load(baz_file)\n",
    "baz_file.close()\n",
    "\n",
    "# get backazimuths of detected events\n",
    "backazimuths = b.backazimuths\n",
    "big_event_backazimuth = backazimuths[14]\n",
    "\n",
    "# get station locations and array centroids\n",
    "station_lon_lat_coords = get_station_coordinates(\"data/XML/\")\n",
    "station_grid_coords = get_station_grid_locations(station_lon_lat_coords,\"epsg:3245\")\n",
    "array_centroid = np.mean(station_grid_coords,axis=0)\n",
    "\n",
    "# open LANDSAT imagery file\n",
    "file = \"data/imagery/LC08_L1GT_001113_20131012_20170429_01_T2_B4.TIF\"\n",
    "transform_imagery(file,'epsg:3245')\n",
    "\n",
    "# set where to split the distribution and which color to use for each\n",
    "colors = [\"#7570b3\",\"#d95f02\"]\n",
    "\n",
    "# make the figure\n",
    "plot_catalog_and_big_event_backazimuths(backazimuths,big_event_backazimuth,array_centroid,station_grid_coords,colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543caacc-4227-45bf-8e34-5043c8fe35a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Investigate which events are coming from the azimuthal range of the new rift branch\n",
    "\n",
    "'''\n",
    "\n",
    "# load catalog \n",
    "detection_times = np.load('outputs/detections.npy',allow_pickle=True)\n",
    "\n",
    "# read backazimuths\n",
    "baz_file = open(\"outputs/event_backazimuths_PIG2_PIG4_PIG5_distance_pca_fixed_centroid.pickle\", \"rb\")\n",
    "b = pickle.load(baz_file)\n",
    "baz_file.close()\n",
    "backazimuths = b.backazimuths\n",
    "\n",
    "# set range of interest\n",
    "baz_range = [280,360]\n",
    "\n",
    "# get data\n",
    "st = obspy.read(\"data/MSEED/may_8-11_velocity_100000s_downsampled.MSEED\")\n",
    "\n",
    "# set low cut periods of data to be dispayed\n",
    "freq = [10,100,1000]\n",
    "\n",
    "# put data into dictionary\n",
    "window_start = obspy.UTCDateTime(2012,5,8,10,18)\n",
    "window_end = obspy.UTCDateTime(2012,5,11,3,13)\n",
    "data_dict = {}\n",
    "for tr in st:\n",
    "    for f in freq: \n",
    "        key = tr.stats.station+tr.stats.channel+str(f)\n",
    "        st_filt = tr.copy().filter(\"highpass\",freq=1/f)\n",
    "        data_dict[key] = st_filt.trim(starttime=window_start,endtime=window_end).data*1000\n",
    "\n",
    "# get time vector\n",
    "t = st_filt.times(type=\"matplotlib\")\n",
    "\n",
    "# make plot\n",
    "nrows = len(freq)\n",
    "fig,ax = plt.subplots(nrows,1,figsize=[15,10])\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "\n",
    "# plot the data\n",
    "for i in range(nrows):\n",
    "    ax[i].plot(t,data_dict[\"PIG2HHZ\"+str(freq[i])], lw=2,color='k')\n",
    "    ax[i].set_title(\"PIG2 HHZ\\n\\n>\"+str(freq[i])+\"s\",y=0.8)\n",
    "    ax[i].set_ylabel(\"Velocity (mm/s)\")\n",
    "    ax[i].set_xlabel(\"Time\")\n",
    "    ax[i].xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\\n%H:%M:%S'))\n",
    "    ax[i].set_xlim([t[0],t[-1]])\n",
    "    ax[nrows-1].get_shared_x_axes().join(ax[nrows-1],ax[i])\n",
    "\n",
    "# define object for updating data when buttons are pressed\n",
    "class metadata:\n",
    "    def __init__(self,station,channel):\n",
    "        self._station = station\n",
    "        self._channel = channel\n",
    "\n",
    "    def select_component(self,component_id,component_type):\n",
    "        def clicked(event):\n",
    "            if component_type == \"station\":\n",
    "                self._station = component_id\n",
    "            if component_type == \"channel\":\n",
    "                self._channel = component_id\n",
    "            for i in range(nrows):\n",
    "                key = self._station+self._channel+str(freq[i])\n",
    "                ax[i].get_lines()[0].set_ydata(data_dict[key])\n",
    "                ax[i].relim()\n",
    "                ax[i].autoscale()\n",
    "                ax[i].set_xlim([t[0],t[-1]])\n",
    "                ax[i].set_title(self._station+\" \"+self._channel+\"\\n\\n>\"+str(freq[i])+\"s\",y=0.8)\n",
    "            plt.draw()\n",
    "        return clicked\n",
    "    \n",
    "def mouse_event(event):\n",
    "    print('x: {} and y: {}'.format(event.xdata, event.ydata))\n",
    "    \n",
    "# make instances of the widget\n",
    "column0 = metadata(\"PIG2\",\"HHZ\")\n",
    "\n",
    "# add each set of buttons\n",
    "axbutton = plt.axes([0.125, 0.075, 0.05, 0.05])\n",
    "pig2_b0 = Button(axbutton, 'PIG2')\n",
    "pig2_b0.on_clicked(column0.select_component(\"PIG2\",\"station\"))\n",
    "axbutton = plt.axes([0.2, 0.075, 0.05, 0.05])\n",
    "pig4_b0 = Button(axbutton, 'PIG4')\n",
    "pig4_b0.on_clicked(column0.select_component(\"PIG4\",\"station\"))\n",
    "axbutton = plt.axes([0.275, 0.075, 0.05, 0.05])\n",
    "pig5_b0 = Button(axbutton, 'PIG5')\n",
    "pig5_b0.on_clicked(column0.select_component(\"PIG5\",\"station\"))\n",
    "plt.text(-4,0.4,\"Stations\")\n",
    "axbutton = plt.axes([0.125, 0.01, 0.05, 0.05])\n",
    "hhz_b0 = Button(axbutton, 'HHZ')\n",
    "hhz_b0.on_clicked(column0.select_component(\"HHZ\",\"channel\"))\n",
    "axbutton = plt.axes([0.2, 0.01, 0.05, 0.05])\n",
    "hhn_b0 = Button(axbutton, 'HHN')\n",
    "hhn_b0.on_clicked(column0.select_component(\"HHN\",\"channel\"))\n",
    "axbutton = plt.axes([0.275, 0.01, 0.05, 0.05])\n",
    "hhe_b0 = Button(axbutton, 'HHE')\n",
    "hhe_b0.on_clicked(column0.select_component(\"HHE\",\"channel\"))\n",
    "plt.text(-4,0.4,\"Channels\")\n",
    "\n",
    "# highlight events in baz range of interest\n",
    "for i in range(len(backazimuths)):\n",
    "    if backazimuths[i] >= baz_range[0] and backazimuths[i] <= baz_range[1]:\n",
    "        for axis in ax:\n",
    "            axis.axvline(detection_times[i][0],0,1,color ='g',linestyle='--')\n",
    "            axis.axvline(detection_times[i][1],0,1,color ='r',linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c27f17-56ac-40f7-a109-971cc792c1f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Investigate relationships between frequency and duration, SNR, and amplitude\n",
    "\n",
    "'''\n",
    "\n",
    "# set parameters \n",
    "big_event_index = 14\n",
    "station = \"PIG2\"\n",
    "channels = [\"HHZ\",\"HHE\",\"HHN\"]\n",
    "freq = [1,10,100,1000,10000]\n",
    "fs = 100\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    \n",
    "# load and sort catalog\n",
    "detection_times = np.load('outputs/detections.npy',allow_pickle=True)\n",
    "sort_indices = np.argsort(detection_times[:,0])\n",
    "detection_times = detection_times[sort_indices]\n",
    "    \n",
    "# get data using workaround for reading large MSEED files with obspy\n",
    "st = obspy.Stream()\n",
    "with io.open(\"data/MSEED/may_8-11_velocity_100000s.MSEED\", \"rb\") as fh:\n",
    "    while True:\n",
    "        with io.BytesIO() as buf:\n",
    "            c = fh.read(512*1000000)\n",
    "            if not c:\n",
    "                break\n",
    "            buf.write(c)\n",
    "            buf.seek(0, 0)\n",
    "            st += obspy.read(buf)\n",
    "st.merge()\n",
    "\n",
    "# put data into dictionary\n",
    "window_start = obspy.UTCDateTime(2012,5,8,10,18)\n",
    "window_end = obspy.UTCDateTime(2012,5,11,3,13)\n",
    "big_event_window_end = [obspy.UTCDateTime(2012,5,9,18,10),obspy.UTCDateTime(2012,5,9,18,10),obspy.UTCDateTime(2012,5,9,18,40),\n",
    "              obspy.UTCDateTime(2012,5,9,20),obspy.UTCDateTime(2012,5,9,20),obspy.UTCDateTime(2012,5,9,20)]\n",
    "data_dict = {}\n",
    "for tr in st:\n",
    "    for f in freq: \n",
    "        key = tr.stats.station+tr.stats.channel+str(f)\n",
    "        st_filt = tr.copy().filter(\"highpass\",freq=1/f)\n",
    "        data_dict[key] = st_filt.trim(starttime=window_start,endtime=window_end).data*1000\n",
    "\n",
    "# make functions that estimate each parameter of interest\n",
    "def get_duration(data):\n",
    "    cumulative_curve = np.cumsum(np.square(data))\n",
    "    max_curve = np.max(cumulative_curve)\n",
    "    finish_amp = 0.95 * max_curve\n",
    "    duration = len(np.where((cumulative_curve<=finish_amp))[0])/fs\n",
    "    return duration\n",
    "\n",
    "def get_snr(data):\n",
    "    snr = get_amplitude(data)/data.std()\n",
    "    return snr\n",
    "\n",
    "def get_amplitude(data):\n",
    "    amplitude = np.max(np.abs(data))\n",
    "    return amplitude\n",
    "\n",
    "def regression(model_vector,data_vector):\n",
    "    model_vector = np.vstack((np.array(model_vector),np.ones((len(model_vector))))).transpose()\n",
    "    m,b = np.linalg.lstsq(model_vector,data_vector,rcond=None)[0]\n",
    "    return m,b\n",
    "\n",
    "# make plot \n",
    "fig,ax = plt.subplots(3,3,figsize=[12,10])\n",
    "for axes in ax:\n",
    "    for axis in axes:\n",
    "        axis.set_xscale('log')\n",
    "for axes in ax[:2]:\n",
    "    for axis in axes:\n",
    "        axis.set_yscale('log')\n",
    "        \n",
    "# iterate through each channel \n",
    "for c in range(len(channels)):\n",
    "    for i in range(len(detection_times)):\n",
    "        duration_vector = []\n",
    "        amplitude_vector = []\n",
    "        snr_vector = []\n",
    "        for f in range(len(freq)):\n",
    "               \n",
    "            # get correct trace\n",
    "            data = data_dict[station+channels[c]+str(freq[f])]\n",
    "            \n",
    "            # trim to just event window\n",
    "            if i == big_event_index:\n",
    "                duration_to_start = detection_times[i][0] - st.trim(starttime=window_start,endtime=window_end)[0].stats.starttime.datetime.replace(tzinfo=timezone.utc)\n",
    "                duration_to_end = big_event_window_end[f].datetime - st.trim(starttime=window_start,endtime=window_end)[0].stats.starttime.datetime\n",
    "            else:  \n",
    "                duration_to_start = detection_times[i][0] - st.trim(starttime=window_start,endtime=window_end)[0].stats.starttime.datetime.replace(tzinfo=timezone.utc)\n",
    "                duration_to_end = detection_times[i][1] - st.trim(starttime=window_start,endtime=window_end)[0].stats.starttime.datetime.replace(tzinfo=timezone.utc)\n",
    "            start_index = fs * (duration_to_start.days*86400+duration_to_start.seconds)\n",
    "            end_index = fs * (duration_to_end.days*86400+duration_to_end.seconds)\n",
    "            data_trim = data[start_index:end_index]\n",
    "            \n",
    "            # estimate each parameter\n",
    "            duration = get_duration(data_trim)\n",
    "            amplitude = get_amplitude(data_trim)           \n",
    "            snr = get_snr(data_trim)           \n",
    "            \n",
    "            # make scatter plot\n",
    "            if i == big_event_index:\n",
    "                color = colors[1]\n",
    "            else:\n",
    "                color = colors[0]\n",
    "                amplitude_vector.append(amplitude)\n",
    "                duration_vector.append(duration)\n",
    "                snr_vector.append(snr)\n",
    "            duration_point = ax[0][c].scatter(1/freq[f],duration,color=color)\n",
    "            amplitude_point = ax[1][c].scatter(1/freq[f],amplitude,color=color)\n",
    "            snr_point = ax[2][c].scatter(1/freq[f],snr,color=color)\n",
    "                \n",
    "        # plot a best fit line for each set of scattered values\n",
    "        #[m,b] = regression(np.log10(np.array(low_cut)),np.log10(duration_vector))\n",
    "        #ax[0][c].plot(low_cut,10**(m*np.log10(np.array(low_cut))+b),'--',color=colors[0],alpha=0.25)\n",
    "        #[m,b] = regression(np.log10(np.array(low_cut)),np.log10(amplitude_vector))\n",
    "        #ax[1][c].plot(low_cut,10**(m*np.log10(np.array(low_cut))+b),'--',color=colors[0],alpha=0.25)\n",
    "\n",
    "ax[0][0].set_title('HHZ')\n",
    "ax[0][1].set_title('HHN')\n",
    "ax[0][2].set_title('HHE')\n",
    "ax[0][0].set_ylabel('Duration (s)')\n",
    "ax[1][0].set_ylabel('Max amplitude (m/s)')\n",
    "ax[2][0].set_ylabel('SNR')\n",
    "for axis in ax[0]:\n",
    "    #axis.set_ylim([10**2,10**4])\n",
    "    axis.set_xticks([1e-4,1e-3,1e-2,1e-1,1])\n",
    "for axis in ax[1]:\n",
    "    #axis.set_ylim([10**(-5),10**(-2.5)])\n",
    "    axis.set_xticks([1e-4,1e-3,1e-2,1e-1,1])\n",
    "for axis in ax[2]:\n",
    "    #axis.set_ylim([2,10])\n",
    "    axis.set_xlabel('Low cutoff frequency (Hz)')\n",
    "    axis.set_xticks([1e-4,1e-3,1e-2,1e-1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26d73ec-d35d-4581-83f6-85f3da99ddc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n",
      "Got all files...\n",
      "\n",
      "Made inputs...\n",
      "\n",
      "Finished with 2012-05-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "\n",
    "Calculate backazimuth through time for big event\n",
    "\n",
    "'''\n",
    "\n",
    "# initialize location parameter object and set parameters for backazimuth computation\n",
    "l = types.SimpleNamespace()\n",
    "l.win_len = 720\n",
    "l.slide = 1\n",
    "l.stations = [\"PIG2\",\"PIG4\",\"PIG5\"]\n",
    "l.network = \"XC\"\n",
    "\n",
    "# set event start time\n",
    "event_start = datetime.datetime(2012, 5, 9, 18, tzinfo=datetime.timezone.utc)\n",
    "event_end = datetime.datetime(2012, 5, 9, 20, tzinfo=datetime.timezone.utc)\n",
    "event_length = (event_end-event_start).seconds\n",
    "\n",
    "# set the coordinate system in which we will do all grid-based calculations\n",
    "l.crs = \"EPSG:3245\"\n",
    "\n",
    "# set signal-to-noise ratio for throwing out stations and sta/lta ratio for throwing out individual windows in backazimuth computation\n",
    "l.snr_threshold = 0\n",
    "l.stalta_threshold = 0\n",
    "\n",
    "# specify method for correcting pca components \n",
    "l.pca_correction = \"distance\"\n",
    "l.centroid = \"fixed\"\n",
    "\n",
    "# specify parameters for cross correlation based determination of station of first arrival\n",
    "l.max_shift = 1000\n",
    "l.freq = [0.05,10]\n",
    "l.fs = 100\n",
    "\n",
    "# specify paths to data and me tadata\n",
    "#l.data_path = \"data/MSEED/no_IR/\"\n",
    "#l.xml_path = \"data/XML/\"\n",
    "l.data_path = \"/media/Data/Data/PIG/MSEED/noIR/\"\n",
    "l.xml_path = \"/media/Data/Data/PIG/XML/HH/\"\n",
    "l.filename = \"outputs/event_backazimuths_\" + '_'.join(l.stations) + \"_\" + l.pca_correction + \"_pca_\" + l.centroid + \"_centroid\"\n",
    "l.n_procs = 10\n",
    "\n",
    "# run the backazimuth code\n",
    "backazimuths = []\n",
    "times = []\n",
    "for t in range(0,event_length,l.win_len):\n",
    "    l.detection_times = np.array([[event_start+datetime.timedelta(seconds=t),event_start+datetime.timedelta(seconds=t+l.win_len)]])\n",
    "    b = compute_backazimuths(l)\n",
    "    backazimuths.extend(b.backazimuths)\n",
    "    times.append(l.detection_times[0]+datetime.timedelta(seconds = l.win_len/2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
